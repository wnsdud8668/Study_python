# -*- coding: utf-8 -*-
"""
Created on Tue Sep  8 02:23:50 2020

@author: junyoung
"""


import numpy as np
import pandas as pd
import matplotlib.pylab as plt
import re
import time
from collections import Counter
from wordcloud import WordCloud
from konlpy.tag import Twitter
from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 
import konlpy 
from konlpy.tag import Okt 


#%%

from konlpy.tag import Okt
from sklearn.feature_extraction.text import TfidfVectorizer

import konlpy 
from konlpy.tag import Okt 
okt=Okt()

#%%
words = []
words.append('ì˜í¬ ì² ìˆ˜ ê°ì‚¬í•©ë‹ˆë‹¤ ì‚¬ê¸° ðŸ˜‚ ë¬´ë£Œ ìµœê³  ã…Žã…Ž ') # ëŒ“ê¸€ì— ì¶”ì¶œëœ í˜•íƒœì†Œ í˜¹ì€ ëª…ì‚¬
words.append('ìµœê³  ì¶•í•˜ ê°ì‚¬í•˜ë‹¤ ë¬´ë£Œ') # ê¸ì • ë‹¨ì–´ ëª©ë¡
words.append('ì¤‘ë‹¨ ì•„ ì‹¤ë§ ì‚¬ê¸° ë¶„ë…¸') # ë¶€ì • ë‹¨ì–´ ëª©ë¡

    
#%%
# 1. ë¶ˆìš©ì–´ ì œê±°
import re
import pandas as pd
from nltk.tokenize import word_tokenize

# ì´ëª¨í‹°ì½˜
emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F"  # emoticons
                u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                u"\U0001F680-\U0001F6FF"  # transport & map symbols
                u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                u'\U00010000-\U0010ffff'  # not BMP characters
    "]+", flags=re.UNICODE)

# íŠ¹ìˆ˜ë¬¸ìž, ì˜ì„±ì–´
han = re.compile(r'[ã„±-ã…Žã…-ã…£!?~,".\n\r#\ufeff\u200d]')

# ì´ëª¨í‹°ì½˜, íŠ¹ìˆ˜ë¬¸ìž, ì˜ì„±ì–´ ì œê±°
word_result = []
for i in words:
    tokens = re.sub(emoji_pattern,"",str(i))
    tokens = re.sub(han,"",tokens)
    word_result.append(tokens)



# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
stop_words = ['ì•„ ê·¸ ì €']

# ë¶ˆìš©ì–´ í† í°í™”
for word in stop_words:
    stop_words_token=word_tokenize(word)

# ë¶ˆìš©ì–´ ì œê±°
token_words=[]
for word in word_result:
    tokens=word_tokenize(str(word))
    words=[]
    for wor in tokens:
        if wor not in stop_words_token:
            words.append(wor)
    token_words.append(words)

print(token_words)

    
#%% í•œêµ­ì–´ ì²˜ë¦¬

from konlpy.tag import Okt 
okt=Okt()

okt.morphs('ê°ì‚¬í•©ë‹ˆë‹¤')

# morphs = í…ìŠ¤íŠ¸ë¥¼ í˜•íƒœì†Œë¡œ ë‚˜ëˆˆë‹¤
# stem = ë‹¨ì–´ì˜ ì–´ê°„ ì¶”ì¶œ
okt.morphs('ê°ì‚¬í•©ë‹ˆë‹¤',stem=True)
okt.morphs('ê°ì‚¬í•˜ë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤ ê°ì‚¬',stem=True)

# pos - í…ìŠ¤íŠ¸ì˜ í’ˆì‚¬ë¥¼ íƒœê·¸
okt.pos('ê°ì‚¬í•©ë‹ˆë‹¤ ê°ì‚¬í•´ìš” ê°ì‚¬í–ˆìŠµë‹ˆë‹¤')

okt.phrases('ê°ì‚¬í•©ë‹ˆë‹¤')


from konlpy.tag import Twitter
twitter=Twitter()

for word in ['í–ˆë‹¤', 'í–ˆì§€ë§Œ', 'í•˜ë©´ì„œë„', 'í–ˆë˜', 'í•˜ë‹ˆê¹Œ']:
    print(twitter.pos(word))


from konlpy.tag import Komoran

Komoran().pos('í–ˆë‹¤') # [('í•˜', 'VV'), ('ì•˜', 'EP'), ('ë‹¤', 'EC')]

a=Komoran().pos('ê°ì‚¬í–ˆìŠµë‹ˆë‹¤ ì‚¬ëž‘í–ˆì–´ìš” ê²Œìž„ ë¡¯ë°ë§ˆíŠ¸ ìµœê³ ì•¼')

for i in a:
    if i[1]=='NNG' or i[1]=='NNP':
        print(i[0])








#%%
# ë¶€ì • ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
f = open('negative_words_self.txt', 'r',encoding='UTF-8')
lines = f.readlines()
f.close()

negative=[]
for i in lines:
    i=i.replace('\n','')
    negative.append(i)
    
#%%
# ì´ëª¨í‹°ì½˜ ì œê±°
emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F"  # emoticons
                u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                u"\U0001F680-\U0001F6FF"  # transport & map symbols
                u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                u'\U00010000-\U0010ffff'  # not BMP characters
    "]+", flags=re.UNICODE)

# ë¶„ì„ì— ì–´ê¸‹ë‚˜ëŠ” ë¶ˆìš©ì–´êµ¬ ì œì™¸ (íŠ¹ìˆ˜ë¬¸ìž, ì˜ì„±ì–´)
han = re.compile(r'[ã„±-ã…Žã…-ã…£!?~,".\n\r#\ufeff\u200d]')
  

comment_result = []
for i in comm:
    tokens = re.sub(emoji_pattern,"",str(i))
    tokens = re.sub(han,"",tokens)
    comment_result.append(tokens)

# ë¶ˆìš©ì–´ ì œê±°
words2=[]
for i in words:
    a=[]
    for z in i:
        if z not in stop_words:
            a.append(z)
    words2.append(a)

words2=[]
for i in words:
    a=[]
    for z in i:
        if z not in stop_words:
            a.append(z)
    words2.append(a)

#%% ë¶ˆìš©ì–´ ì œê±°

# ë¶ˆìš©ì–´ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
f = open('ë¶ˆìš©ì–´ë¦¬ìŠ¤íŠ¸.txt', 'r',encoding='UTF-8')
lines = f.readlines()
f.close()
stop_words=[]
for i in lines:
    stop_words.append(i.replace('\n',''))
print(stop_words)

# í† í°í™”
words=[]
for i in range(len(df_comment_result)):
    word_tokens=[]
    word_tokens = word_tokenize(str(df_comment_result['comment'].iloc[i]))
    print(word_tokens)
    words.append(word_tokens)

# ë¶ˆìš©ì–´ ì œê±°
words2=[]
for i in words:
    a=[]
    for z in i:
        if z not in stop_words:
            a.append(z)
    words2.append(a)

#%% í˜•íƒœì†Œ ì¶”ì¶œ
    

words4=[]
for i in words2:
    c=[]
    for z in i:
        b=okt.morphs(str(z),stem=True)
        c.append(' '.join(b))
    words4.append(' '.join(c).split())

words2=words4
#%% 

#1. commentì˜ ë‹¨ì–´ê°€ positive,negative ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ì— ìžˆëŠ”ì§€ í™•ì¸

label=[]    

for i in words2:
    pos=0
    neg=0
    for z in i:
        
        if z in positive:
            pos+=1
        elif z in negative:
            neg+=1
    if pos>neg:
        label.append('1')
    elif pos<neg:
        label.append('-1')
    else:
        label.append('0')

#%%
from sklearn.feature_extraction.text import TfidfVectorizer
#2. ìœ ì‚¬ë„ ì¸¡ì •

tfidf_vectorizer=TfidfVectorizer()
words

tfidf_vectorizer = TfidfVectorizer(min_df=1)

label2=[]
for i in words2:
    a=[]
    a.append(' '.join(i))
    a.append(' '.join(positive))
    a.append(' '.join(negative))
    tfidf_matrix_twitter = tfidf_vectorizer.fit_transform(a)
    document_distance = (tfidf_matrix_twitter * tfidf_matrix_twitter.T)
    if document_distance.toarray()[0][1] > document_distance.toarray()[0][2]:
        label2.append('1')
    elif document_distance.toarray()[0][1] < document_distance.toarray()[0][2]:
        label2.append('-1')
    else:
        label2.append('0')

#%%
comment_valid=pd.DataFrame(columns=['comment','ë‹¨ì–´í¬í•¨ì—¬ë¶€','ìœ ì‚¬ë„ì¸¡ì •'])
comment_valid['comment']=words2
comment_valid['ë‹¨ì–´í¬í•¨ì—¬ë¶€']=label
comment_valid['ìœ ì‚¬ë„ì¸¡ì •']=label2

comment_valid['ë‹¨ì–´í¬í•¨ì—¬ë¶€'].value_counts().plot(kind='bar')

